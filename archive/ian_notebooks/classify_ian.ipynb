{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Tweet Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    print(\"Initial dataframe length: \", len(df))\n",
    "\n",
    "    # drop NAs\n",
    "    df = df.dropna()\n",
    "    # drop duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    df['text'] = df['text'].apply(str)\n",
    "    \n",
    "    print(\"# of Unique ID's: \", len(df.id.unique()))\n",
    "    print(\"Final dataframe length: \", len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test2'\n",
    "input_filename = \"../twitter_data/ian_scraped_tweets/\"+filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'date', 'fullname', 'id', 'likes', 'replies', 'retweets',\n",
       "       'text', 'url', 'user', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames= ['index','date', 'fullname', 'id', 'likes', 'replies', 'retweets', 'text', 'url', 'user', 'month']\n",
    "df = pd.read_csv(input_filename, encoding = \"ISO-8859-1\", names=colnames)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataframe length:  572\n",
      "# of Unique ID's:  572\n",
      "Final dataframe length:  572\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>fullname</th>\n",
       "      <th>id</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>user</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01 23:59:54</td>\n",
       "      <td>New Republitarian</td>\n",
       "      <td>947980735717265409</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>If \"Dreamers\" were known to lean 80+% Republic...</td>\n",
       "      <td>/NuRepublitarian/status/947980735717265409</td>\n",
       "      <td>NuRepublitarian</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 23:59:51</td>\n",
       "      <td>Fuck DACA</td>\n",
       "      <td>947980722517757952</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Maybe they are in fear of deportation because ...</td>\n",
       "      <td>/daca_fuck/status/947980722517757952</td>\n",
       "      <td>daca_fuck</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-01 23:59:43</td>\n",
       "      <td>Politicallady</td>\n",
       "      <td>947980686786473984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>But what about the DACA children? #DACA</td>\n",
       "      <td>/Politicallady9/status/947980686786473984</td>\n",
       "      <td>Politicallady9</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                 date           fullname                  id  likes  \\\n",
       "0      0  2018-01-01 23:59:54  New Republitarian  947980735717265409      2   \n",
       "1      1  2018-01-01 23:59:51          Fuck DACA  947980722517757952      0   \n",
       "2      2  2018-01-01 23:59:43      Politicallady  947980686786473984      0   \n",
       "\n",
       "   replies  retweets                                               text  \\\n",
       "0        0         3  If \"Dreamers\" were known to lean 80+% Republic...   \n",
       "1        1         0  Maybe they are in fear of deportation because ...   \n",
       "2        0         0            But what about the DACA children? #DACA   \n",
       "\n",
       "                                          url             user       month  \n",
       "0  /NuRepublitarian/status/947980735717265409  NuRepublitarian  2018-01-01  \n",
       "1        /daca_fuck/status/947980722517757952        daca_fuck  2018-01-01  \n",
       "2   /Politicallady9/status/947980686786473984   Politicallady9  2018-01-01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(input_filename, encoding = \"ISO-8859-1\",\n",
    "#                 usecols = ['date', 'fullname', 'id', 'likes', 'replies', \n",
    "#                            'retweets', 'text', 'url', 'user', 'month'])\n",
    "df = pre_process(df)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize tweets and predict toxicity with model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'LemmaTokenizer' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-93da29b88c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load vectorizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../toxicity_models/word_vectorizer.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mchar_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../toxicity_models/char_vectorizer.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'LemmaTokenizer' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "# Load vectorizers\n",
    "word_vectorizer = pickle.load(open(\"../toxicity_models/word_vectorizer.pickle\", \"rb\" ))\n",
    "char_vectorizer = pickle.load(open(\"../toxicity_models/char_vectorizer.pickle\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize tweets\n",
    "tweet_word_features = word_vectorizer.transform(df['text'])\n",
    "tweet_char_features = char_vectorizer.transform(df['text'])\n",
    "tweet_features = hstack([tweet_word_features, tweet_char_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "loaded_models = {}\n",
    "for col in target_columns:\n",
    "    loaded_models[col] = pickle.load(open('../toxicity_models/model_{}.sav'.format(col), \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run models\n",
    "for col in target_columns:\n",
    "    df[col] = loaded_models[col].predict_proba(tweet_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>fullname</th>\n",
       "      <th>id</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>user</th>\n",
       "      <th>month</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-13 23:59:48</td>\n",
       "      <td>The Rose Bushes</td>\n",
       "      <td>918989678929436673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Undocumented Teen Held In Texas Is At The Hear...</td>\n",
       "      <td>/TheRoseBushes/status/918989678929436673</td>\n",
       "      <td>TheRoseBushes</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>0.025666</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-13 23:59:17</td>\n",
       "      <td>Mr. Matthew</td>\n",
       "      <td>918989549640052736</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.youtube.com/watch?v=IPl5bCcwMMo&amp;t=...</td>\n",
       "      <td>/MattSmith1776/status/918989549640052736</td>\n",
       "      <td>MattSmith1776</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-13 23:59:15</td>\n",
       "      <td>Everything</td>\n",
       "      <td>918989540240576514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New story on NPR: Undocumented Teen Held In Te...</td>\n",
       "      <td>/iTweet_News/status/918989540240576514</td>\n",
       "      <td>iTweet_News</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>0.059671</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date         fullname                  id  likes  replies  \\\n",
       "0  2017-10-13 23:59:48  The Rose Bushes  918989678929436673    0.0      0.0   \n",
       "1  2017-10-13 23:59:17      Mr. Matthew  918989549640052736    2.0      1.0   \n",
       "2  2017-10-13 23:59:15       Everything  918989540240576514    0.0      0.0   \n",
       "\n",
       "   retweets                                               text  \\\n",
       "0       0.0  Undocumented Teen Held In Texas Is At The Hear...   \n",
       "1       1.0  https://www.youtube.com/watch?v=IPl5bCcwMMo&t=...   \n",
       "2       0.0  New story on NPR: Undocumented Teen Held In Te...   \n",
       "\n",
       "                                        url           user       month  \\\n",
       "0  /TheRoseBushes/status/918989678929436673  TheRoseBushes  2017-10-01   \n",
       "1  /MattSmith1776/status/918989549640052736  MattSmith1776  2017-10-01   \n",
       "2    /iTweet_News/status/918989540240576514    iTweet_News  2017-10-01   \n",
       "\n",
       "      toxic  severe_toxic   obscene    threat    insult  identity_hate  \\\n",
       "0  0.025666      0.001729  0.001311  0.000047  0.000224       0.000089   \n",
       "1  0.008181      0.000374  0.001491  0.000025  0.000939       0.000108   \n",
       "2  0.059671      0.001845  0.002058  0.000102  0.000445       0.000101   \n",
       "\n",
       "  classification  \n",
       "0          toxic  \n",
       "1          toxic  \n",
       "2          toxic  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['classification'] = df[target_columns].idxmax(axis=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export df\n",
    "filename = \"classified\"+filename[6:]\n",
    "export_filename = \"../classified/ian/\"+filename\n",
    "df.to_csv(export_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: toxic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b468bbced265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# visualize obscenity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'toxic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Column not found: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: toxic'"
     ]
    }
   ],
   "source": [
    "# visualize obscenity\n",
    "df.groupby('date')['toxic'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a289e8518>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['likes'] = df['likes'].astype(float)\n",
    "\n",
    "# normalizing identity hate by tweet popularity\n",
    "df['popular_obscene'] = df['obscene']*df['likes']\n",
    "df.groupby('date')['popular_obscene'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a289e8518>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizing identity hate by number of popular tweets\n",
    "(df.groupby('date')['popular_obscene'].sum() / df.groupby('date')['likes'].sum()).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a289e8518>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizing popular tweets by number of popular tweets\n",
    "(df.groupby('date')['popular_obscene'].sum() / df.groupby('date')['likes'].count()).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
