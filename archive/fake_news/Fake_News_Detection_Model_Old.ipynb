{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import machine learning libraries from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liar_train = pd.read_excel(\"liar_dataset/liar_train.xlsx\", header=None, usecols=[1, 2])\n",
    "liar_test = pd.read_excel(\"liar_dataset/liar_test.xlsx\", header=None, usecols=[1, 2])\n",
    "liar_valid = pd.read_excel(\"liar_dataset/liar_valid.xlsx\", header=None, usecols=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liar_datasets = [liar_train, liar_test, liar_valid]\n",
    "df = pd.concat(liar_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns= ['label', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12791</td>\n",
       "      <td>12791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6</td>\n",
       "      <td>12765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>half-true</td>\n",
       "      <td>On a cap-and-trade plan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2627</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                      text\n",
       "count       12791                     12791\n",
       "unique          6                     12765\n",
       "top     half-true  On a cap-and-trade plan.\n",
       "freq         2627                         3"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, 'half-true', 'mostly-true', True, 'barely-true', 'pants-fire'], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode labels as numbers\n",
    "df.loc[df['label'] == \"pants-fire\", 'label'] = 0\n",
    "df.loc[df['label'] == False, 'label'] = 0\n",
    "df.loc[df['label'] == \"mostly-true\", 'label'] = 1\n",
    "df.loc[df['label'] == True, 'label'] = 1\n",
    "\n",
    "# drop half-true\n",
    "df = df.drop(df[df['label'] == \"half-true\"].index)\n",
    "df = df.drop(df[df['label'] == \"barely-true\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6601,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert type to int for sklearn model\n",
    "y = df.label.astype(int) \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6601, 2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the shapes of y and df match\n",
    "df.drop(\"label\", axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test & train sets:\n",
      "(4422,) (2179,) (4422,) (2179,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.33, random_state=42, shuffle=False)\n",
    "print('Shape of test & train sets:')\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bag of Words Vectorizer\n",
    "\n",
    "# Initialize the 'count_vectorizer'\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training data \n",
    "count_train = count_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '02',\n",
       " '024',\n",
       " '033',\n",
       " '04',\n",
       " '05',\n",
       " '07',\n",
       " '09',\n",
       " '10',\n",
       " '100',\n",
       " '100th',\n",
       " '103',\n",
       " '10315',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '1070',\n",
       " '109',\n",
       " '10932',\n",
       " '10th',\n",
       " '11',\n",
       " '110',\n",
       " '11023',\n",
       " '11191',\n",
       " '111th',\n",
       " '112',\n",
       " '112th',\n",
       " '114',\n",
       " '115',\n",
       " '11th',\n",
       " '12',\n",
       " '120',\n",
       " '12189',\n",
       " '124',\n",
       " '125',\n",
       " '12670',\n",
       " '128',\n",
       " '12853',\n",
       " '12th',\n",
       " '13',\n",
       " '130',\n",
       " '131',\n",
       " '133',\n",
       " '135',\n",
       " '136',\n",
       " '137',\n",
       " '13th',\n",
       " '14',\n",
       " '140',\n",
       " '141',\n",
       " '143',\n",
       " '144',\n",
       " '145',\n",
       " '14th',\n",
       " '15',\n",
       " '150',\n",
       " '1508',\n",
       " '154',\n",
       " '155',\n",
       " '156',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '163',\n",
       " '165',\n",
       " '168',\n",
       " '168k',\n",
       " '16th',\n",
       " '17',\n",
       " '170',\n",
       " '172',\n",
       " '174',\n",
       " '176',\n",
       " '1789',\n",
       " '1790',\n",
       " '1792',\n",
       " '1798',\n",
       " '17th',\n",
       " '18',\n",
       " '180',\n",
       " '1800s',\n",
       " '181',\n",
       " '1835',\n",
       " '1888',\n",
       " '18th',\n",
       " '19',\n",
       " '190',\n",
       " '1912',\n",
       " '1915',\n",
       " '1917',\n",
       " '1920s',\n",
       " '1928',\n",
       " '1930',\n",
       " '1930s',\n",
       " '194',\n",
       " '1947',\n",
       " '195',\n",
       " '1950',\n",
       " '1954',\n",
       " '1956',\n",
       " '1958',\n",
       " '1960',\n",
       " '1960s',\n",
       " '1961',\n",
       " '1964',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970s',\n",
       " '1972',\n",
       " '1973',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1981',\n",
       " '1982',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1990',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '1absentee',\n",
       " '1one',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2003bushtax',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2019',\n",
       " '2020',\n",
       " '2023',\n",
       " '2025',\n",
       " '2030',\n",
       " '2033',\n",
       " '2040',\n",
       " '2060s',\n",
       " '2070',\n",
       " '2096',\n",
       " '20th',\n",
       " '21',\n",
       " '210',\n",
       " '211',\n",
       " '214',\n",
       " '219',\n",
       " '21st',\n",
       " '22',\n",
       " '224',\n",
       " '228',\n",
       " '23',\n",
       " '2301',\n",
       " '236',\n",
       " '237',\n",
       " '24',\n",
       " '240',\n",
       " '247',\n",
       " '248',\n",
       " '25',\n",
       " '250',\n",
       " '257',\n",
       " '25th',\n",
       " '26',\n",
       " '269',\n",
       " '27',\n",
       " '270',\n",
       " '271',\n",
       " '2724',\n",
       " '275',\n",
       " '278',\n",
       " '28',\n",
       " '280',\n",
       " '29',\n",
       " '290',\n",
       " '2nd',\n",
       " '30',\n",
       " '300',\n",
       " '300k',\n",
       " '30s',\n",
       " '31',\n",
       " '310',\n",
       " '315',\n",
       " '32',\n",
       " '320',\n",
       " '322',\n",
       " '33',\n",
       " '331',\n",
       " '333',\n",
       " '336',\n",
       " '34',\n",
       " '35',\n",
       " '350',\n",
       " '36',\n",
       " '360',\n",
       " '3666',\n",
       " '37',\n",
       " '370',\n",
       " '376',\n",
       " '38',\n",
       " '385',\n",
       " '39',\n",
       " '391',\n",
       " '3m',\n",
       " '3rds',\n",
       " '40',\n",
       " '400',\n",
       " '400k',\n",
       " '401',\n",
       " '40s',\n",
       " '41',\n",
       " '41st',\n",
       " '42',\n",
       " '420',\n",
       " '428',\n",
       " '43',\n",
       " '431',\n",
       " '435',\n",
       " '439',\n",
       " '43rd',\n",
       " '44',\n",
       " '44th',\n",
       " '45',\n",
       " '450',\n",
       " '451',\n",
       " '455',\n",
       " '46',\n",
       " '4608',\n",
       " '46th',\n",
       " '47',\n",
       " '475',\n",
       " '47th',\n",
       " '48',\n",
       " '485',\n",
       " '48th',\n",
       " '49',\n",
       " '49th',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '504',\n",
       " '5076',\n",
       " '50th',\n",
       " '51',\n",
       " '5122',\n",
       " '52',\n",
       " '525',\n",
       " '53',\n",
       " '535',\n",
       " '54',\n",
       " '540',\n",
       " '55',\n",
       " '550',\n",
       " '551',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '5802',\n",
       " '587',\n",
       " '59',\n",
       " '590',\n",
       " '60',\n",
       " '600',\n",
       " '601',\n",
       " '60s',\n",
       " '61',\n",
       " '6153',\n",
       " '62',\n",
       " '620',\n",
       " '624',\n",
       " '63',\n",
       " '64',\n",
       " '643',\n",
       " '65',\n",
       " '650',\n",
       " '6515',\n",
       " '657',\n",
       " '66',\n",
       " '668',\n",
       " '67',\n",
       " '68',\n",
       " '685',\n",
       " '696',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '70s',\n",
       " '71',\n",
       " '72',\n",
       " '722',\n",
       " '729',\n",
       " '73',\n",
       " '731',\n",
       " '733',\n",
       " '74',\n",
       " '75',\n",
       " '750',\n",
       " '76',\n",
       " '760',\n",
       " '77',\n",
       " '777',\n",
       " '78',\n",
       " '787',\n",
       " '78702',\n",
       " '79',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '803',\n",
       " '805',\n",
       " '808',\n",
       " '80s',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '840',\n",
       " '85',\n",
       " '850',\n",
       " '855',\n",
       " '86',\n",
       " '87',\n",
       " '877',\n",
       " '88',\n",
       " '89',\n",
       " '890',\n",
       " '8th',\n",
       " '90',\n",
       " '900',\n",
       " '91',\n",
       " '918',\n",
       " '92',\n",
       " '924',\n",
       " '932',\n",
       " '94',\n",
       " '945',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '992',\n",
       " '9th',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaron',\n",
       " 'aarp',\n",
       " 'abandoned',\n",
       " 'abbas',\n",
       " 'abbott',\n",
       " 'abc',\n",
       " 'abedin',\n",
       " 'abele',\n",
       " 'abide',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abillion',\n",
       " 'able',\n",
       " 'abolish',\n",
       " 'abolishes',\n",
       " 'abolishing',\n",
       " 'abolition',\n",
       " 'abort',\n",
       " 'aborted',\n",
       " 'aborting',\n",
       " 'abortion',\n",
       " 'abortioneven',\n",
       " 'abortionists',\n",
       " 'abortions',\n",
       " 'abraham',\n",
       " 'abrahamlincoln',\n",
       " 'abramoff',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'abu',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'academic',\n",
       " 'academies',\n",
       " 'academy',\n",
       " 'accelerate',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidents',\n",
       " 'accommodate',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountant',\n",
       " 'accounted',\n",
       " 'accounts',\n",
       " 'accumulate',\n",
       " 'accurate',\n",
       " 'accused',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'acentral',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achieving',\n",
       " 'acidic',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'aclu',\n",
       " 'acorn',\n",
       " 'acquire',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'acre',\n",
       " 'acres',\n",
       " 'act',\n",
       " 'actalters',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activated',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adequately',\n",
       " 'adjusted',\n",
       " 'adler',\n",
       " 'admin',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administration',\n",
       " 'administrations',\n",
       " 'administrative',\n",
       " 'admiral',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admonished',\n",
       " 'adolf',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advertising',\n",
       " 'advised',\n",
       " 'adviser',\n",
       " 'advisers',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisory',\n",
       " 'advocacy',\n",
       " 'advocate',\n",
       " 'advocated',\n",
       " 'advocates',\n",
       " 'advocating',\n",
       " 'afc',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affects',\n",
       " 'affecttheir',\n",
       " 'affiliation',\n",
       " 'affirmative',\n",
       " 'afford',\n",
       " 'affordability',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'affront',\n",
       " 'afghan',\n",
       " 'afghanistan',\n",
       " 'afl',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afscme',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'age',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggie',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'agreements',\n",
       " 'agrees',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'ahead',\n",
       " 'ahmadinejad',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aides',\n",
       " 'aids',\n",
       " 'aig',\n",
       " 'ailments',\n",
       " 'aimed',\n",
       " 'air',\n",
       " 'airbus',\n",
       " 'aircraft',\n",
       " 'aired',\n",
       " 'airline',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airs',\n",
       " 'airstrikes',\n",
       " 'airwaves',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alabamas',\n",
       " 'alan',\n",
       " 'alarming',\n",
       " 'alaska',\n",
       " 'alaskan',\n",
       " 'alaskas',\n",
       " 'alcohol',\n",
       " 'alcoholics',\n",
       " 'aleading',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alfred',\n",
       " 'algeria',\n",
       " 'ali',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'aliens',\n",
       " 'aligned',\n",
       " 'alison',\n",
       " 'allan',\n",
       " 'allegation',\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allen',\n",
       " 'allencast',\n",
       " 'alleviating',\n",
       " 'alliance',\n",
       " 'allies',\n",
       " 'alligator',\n",
       " 'allocation',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'als',\n",
       " 'alter',\n",
       " 'altered',\n",
       " 'alternative',\n",
       " 'aluminum',\n",
       " 'amajority',\n",
       " 'amash',\n",
       " 'amassing',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'ambassador',\n",
       " 'ambassadors',\n",
       " 'amber',\n",
       " 'ambitious',\n",
       " 'amend',\n",
       " 'amendment',\n",
       " 'amendmentlanguage',\n",
       " 'amendments',\n",
       " 'amenities',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'americanscan',\n",
       " 'americanscant',\n",
       " 'americanschools',\n",
       " 'americas',\n",
       " 'amid',\n",
       " 'amiddle',\n",
       " 'ammunition',\n",
       " 'amnesty',\n",
       " 'amounting',\n",
       " 'amounts',\n",
       " 'ample',\n",
       " 'amtrak',\n",
       " 'analysis',\n",
       " 'analysts',\n",
       " 'ancestors',\n",
       " 'anchor',\n",
       " 'anderson',\n",
       " 'andrew',\n",
       " 'andso',\n",
       " 'andwas',\n",
       " 'andy',\n",
       " 'angeles',\n",
       " 'angle',\n",
       " 'anglers',\n",
       " 'anglo',\n",
       " 'anglos',\n",
       " 'angry',\n",
       " 'anight',\n",
       " 'animal',\n",
       " 'anita',\n",
       " 'ankle',\n",
       " 'ankrum',\n",
       " 'ann',\n",
       " 'annexation',\n",
       " 'anniversary',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announces',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'anonymous',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'anthem',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'antichrist',\n",
       " 'antidepressant',\n",
       " 'antitrust',\n",
       " 'antonin',\n",
       " 'antonio',\n",
       " 'ants',\n",
       " 'anybody',\n",
       " 'anybodys',\n",
       " 'anymore',\n",
       " 'apartheid',\n",
       " 'apartment',\n",
       " 'apear',\n",
       " 'apiece',\n",
       " 'apologize',\n",
       " 'apology',\n",
       " 'apostle',\n",
       " 'appalachian',\n",
       " 'apparatus',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appealing',\n",
       " 'appeals',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appearances',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'apples',\n",
       " 'applicant',\n",
       " 'applicants',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'appointees',\n",
       " 'appointments',\n",
       " 'appraisal',\n",
       " 'appraises',\n",
       " 'appreciation',\n",
       " 'apprehended',\n",
       " 'apprehensions',\n",
       " 'approach',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriated',\n",
       " 'appropriately',\n",
       " 'appropriation',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approves',\n",
       " 'approving',\n",
       " 'approximately',\n",
       " 'april',\n",
       " 'aprovision',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arbitration',\n",
       " 'arctic',\n",
       " 'area',\n",
       " 'areaswho',\n",
       " 'aren',\n",
       " 'arenas',\n",
       " 'arent',\n",
       " 'argued',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'arising',\n",
       " 'ariz',\n",
       " 'arizona',\n",
       " 'arizonans',\n",
       " 'arkansas',\n",
       " 'arlen',\n",
       " 'arm',\n",
       " 'armed',\n",
       " 'armor',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arrests',\n",
       " 'arriving',\n",
       " 'arrow',\n",
       " 'arsenal',\n",
       " 'art',\n",
       " 'arthritis',\n",
       " 'arthur',\n",
       " 'artificial',\n",
       " 'arts',\n",
       " 'arvada',\n",
       " 'asbig',\n",
       " 'ashbritt',\n",
       " 'ashe',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'aspects',\n",
       " 'assassination',\n",
       " 'assault',\n",
       " 'assaulted',\n",
       " 'assaults',\n",
       " 'assemblies',\n",
       " 'assembly',\n",
       " 'assemblywoman',\n",
       " 'assertions',\n",
       " 'assessment',\n",
       " 'assessments',\n",
       " 'assets',\n",
       " 'assigned',\n",
       " 'assimilation',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'assisting',\n",
       " 'assists',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assumption',\n",
       " 'assure',\n",
       " 'asthma',\n",
       " 'astronauts',\n",
       " 'astronomical',\n",
       " 'asylum',\n",
       " 'atf',\n",
       " 'atheists',\n",
       " 'atlanta',\n",
       " 'atlantas',\n",
       " 'atmosphere',\n",
       " 'atms',\n",
       " 'atomic',\n",
       " 'attached',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attackers',\n",
       " 'attacking',\n",
       " 'attacks',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attend',\n",
       " 'attendance',\n",
       " 'attended',\n",
       " 'attention',\n",
       " 'attitudes',\n",
       " 'attorney',\n",
       " 'attorneys',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attributed',\n",
       " 'attrition',\n",
       " 'atvs',\n",
       " 'au',\n",
       " 'audit',\n",
       " 'auditor',\n",
       " 'audits',\n",
       " 'aug',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'auschwitz',\n",
       " 'ausley',\n",
       " 'ausleys',\n",
       " 'austerity',\n",
       " 'austin',\n",
       " 'austinites',\n",
       " 'austins',\n",
       " 'australia',\n",
       " 'authored',\n",
       " 'authority',\n",
       " 'authorize',\n",
       " 'authorized',\n",
       " 'authorizes',\n",
       " 'autism',\n",
       " 'auto',\n",
       " 'autocrats',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'automobile',\n",
       " 'automobiles',\n",
       " 'available',\n",
       " 'average',\n",
       " 'averaged',\n",
       " 'avert',\n",
       " 'aviation',\n",
       " 'avid',\n",
       " 'avoid',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'axelrod',\n",
       " 'ayers',\n",
       " 'ayotte',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'bachelors',\n",
       " 'bachmann',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'backing',\n",
       " 'backlog',\n",
       " 'backrooms',\n",
       " 'backwards',\n",
       " 'backyard',\n",
       " 'bad',\n",
       " 'bader',\n",
       " 'badger',\n",
       " 'badgercare',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'baghdadi',\n",
       " 'bags',\n",
       " 'bailed',\n",
       " 'bailey',\n",
       " 'bailout',\n",
       " 'bailouts',\n",
       " 'bain',\n",
       " 'baiting',\n",
       " 'baker',\n",
       " 'bakr',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'bald',\n",
       " 'baldwin',\n",
       " 'ballast',\n",
       " 'ballot',\n",
       " 'ballots',\n",
       " 'ballparks',\n",
       " 'balls',\n",
       " 'baltimore',\n",
       " 'ban',\n",
       " 'banana',\n",
       " 'banfield',\n",
       " 'bank',\n",
       " 'banking',\n",
       " 'bankrolling',\n",
       " 'bankrupt',\n",
       " 'bankruptcies',\n",
       " 'bankruptcy',\n",
       " 'bankrupting',\n",
       " 'banks',\n",
       " 'banned',\n",
       " 'banning',\n",
       " 'bans',\n",
       " 'bar',\n",
       " 'barack',\n",
       " 'barbara',\n",
       " 'barbaric',\n",
       " 'barbecue',\n",
       " 'barehanded',\n",
       " 'barely',\n",
       " 'bargaining',\n",
       " 'barking',\n",
       " 'barr',\n",
       " 'barred',\n",
       " 'barrel',\n",
       " 'barrels',\n",
       " 'barrett',\n",
       " 'barretts',\n",
       " 'barriers',\n",
       " 'barry',\n",
       " 'bars',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'bases',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'basketball',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'bathrooms',\n",
       " 'bathtubs',\n",
       " 'battle',\n",
       " 'battlefield',\n",
       " 'battlefields',\n",
       " 'battleground',\n",
       " 'baucus',\n",
       " 'bay',\n",
       " 'bbq',\n",
       " 'beach',\n",
       " 'beaches',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'bears',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beating',\n",
       " 'beaverton',\n",
       " 'becauseblue',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'beds',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'began',\n",
       " 'begich',\n",
       " 'begin',\n",
       " ...]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "\n",
    "# Initialize the 'tfidf_vectorizer'\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7) \n",
    "\n",
    "# Fit and transform the training data \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words & Random Forest Classifier accuracy: 0.589\n",
      "TF-IDF & Random Forest Classifier accuracy: 0.601\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(count_train, y_train)\n",
    "pred1 = rf.predict(count_test)\n",
    "score = accuracy_score(y_test, pred1)\n",
    "print(\"Bag of Words & Random Forest Classifier accuracy: %0.3f\" % score)\n",
    "\n",
    "rf.fit(tfidf_train, y_train)\n",
    "pred2 = rf.predict(tfidf_test)\n",
    "score = accuracy_score(y_test, pred2)\n",
    "print(\"TF-IDF & Random Forest Classifier accuracy: %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances = zip(count_vectorizer.get_feature_names(), rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = pd.DataFrame()\n",
    "aaa['feature'] = count_vectorizer.get_feature_names()\n",
    "aaa['importance'] = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6385</th>\n",
       "      <td>says</td>\n",
       "      <td>0.009728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5330</th>\n",
       "      <td>percent</td>\n",
       "      <td>0.009236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>care</td>\n",
       "      <td>0.006114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>obama</td>\n",
       "      <td>0.005764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7928</th>\n",
       "      <td>year</td>\n",
       "      <td>0.005726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>barack</td>\n",
       "      <td>0.005691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>president</td>\n",
       "      <td>0.004841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5327</th>\n",
       "      <td>people</td>\n",
       "      <td>0.004068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>0.003853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>plan</td>\n",
       "      <td>0.003833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>half</td>\n",
       "      <td>0.003824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>obamacare</td>\n",
       "      <td>0.003687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>states</td>\n",
       "      <td>0.003626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>medicare</td>\n",
       "      <td>0.003623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>average</td>\n",
       "      <td>0.003585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>rep</td>\n",
       "      <td>0.003581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>years</td>\n",
       "      <td>0.003541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7859</th>\n",
       "      <td>wisconsin</td>\n",
       "      <td>0.003370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7134</th>\n",
       "      <td>tax</td>\n",
       "      <td>0.003317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>million</td>\n",
       "      <td>0.003256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>scott</td>\n",
       "      <td>0.003226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>health</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>social</td>\n",
       "      <td>0.003116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6848</th>\n",
       "      <td>state</td>\n",
       "      <td>0.003083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>away</td>\n",
       "      <td>0.003029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>spending</td>\n",
       "      <td>0.003012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>government</td>\n",
       "      <td>0.002961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6093</th>\n",
       "      <td>republicans</td>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>national</td>\n",
       "      <td>0.002910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.002851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>hillsborough</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3562</th>\n",
       "      <td>hole</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>hillarys</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>hillarycare</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>hiked</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>hijacked</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>highways</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>highway</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>highly</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>hogs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>hollen</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>hottest</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3589</th>\n",
       "      <td>hood</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3607</th>\n",
       "      <td>hostages</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606</th>\n",
       "      <td>host</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3604</th>\n",
       "      <td>hospitalized</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>horrendous</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>hopes</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>hopeful</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>hook</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3586</th>\n",
       "      <td>honeymoon</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>hollow</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>honey</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>honest</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>homeowner</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3572</th>\n",
       "      <td>homeland</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>holy</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>hologram</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>holly</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7955</th>\n",
       "      <td>zoo</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7956 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  importance\n",
       "6385          says    0.009728\n",
       "5330       percent    0.009236\n",
       "1358          care    0.006114\n",
       "4965         obama    0.005764\n",
       "7928          year    0.005726\n",
       "946         barack    0.005691\n",
       "5591     president    0.004841\n",
       "5327        people    0.004068\n",
       "1              000    0.003853\n",
       "5426          plan    0.003833\n",
       "3397          half    0.003824\n",
       "4966     obamacare    0.003687\n",
       "6854        states    0.003626\n",
       "4600      medicare    0.003623\n",
       "881        average    0.003585\n",
       "6057           rep    0.003581\n",
       "7929         years    0.003541\n",
       "7859     wisconsin    0.003370\n",
       "7134           tax    0.003317\n",
       "4676       million    0.003256\n",
       "6429         scott    0.003226\n",
       "3473        health    0.003166\n",
       "6705        social    0.003116\n",
       "6848         state    0.003083\n",
       "890           away    0.003029\n",
       "6781      spending    0.003012\n",
       "3298    government    0.002961\n",
       "6093   republicans    0.002953\n",
       "4842      national    0.002910\n",
       "1316      campaign    0.002851\n",
       "...            ...         ...\n",
       "3533  hillsborough    0.000000\n",
       "3562          hole    0.000000\n",
       "3532      hillarys    0.000000\n",
       "3530   hillarycare    0.000000\n",
       "3525         hiked    0.000000\n",
       "3522      hijacked    0.000000\n",
       "3521      highways    0.000000\n",
       "3520       highway    0.000000\n",
       "3519        highly    0.000000\n",
       "3556          hogs    0.000000\n",
       "3564        hollen    0.000000\n",
       "3609       hottest    0.000000\n",
       "3589          hood    0.000000\n",
       "3607      hostages    0.000000\n",
       "3606          host    0.000000\n",
       "3604  hospitalized    0.000000\n",
       "3599    horrendous    0.000000\n",
       "3596         hopes    0.000000\n",
       "3594       hopeful    0.000000\n",
       "3590          hook    0.000000\n",
       "3586     honeymoon    0.000000\n",
       "3565        hollow    0.000000\n",
       "3585         honey    0.000000\n",
       "3584        honest    0.000000\n",
       "3575     homeowner    0.000000\n",
       "3572      homeland    0.000000\n",
       "3569          holy    0.000000\n",
       "3568      hologram    0.000000\n",
       "3566         holly    0.000000\n",
       "7955           zoo    0.000000\n",
       "\n",
       "[7956 rows x 2 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa.sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words & Naive Bayes Classifier accuracy: 0.612\n",
      "TF-IDF & Naive Bayes Classifier accuracy: 0.613\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB() \n",
    "\n",
    "clf.fit(count_train, y_train)\n",
    "pred3 = clf.predict(count_test)\n",
    "score = accuracy_score(y_test, pred3)\n",
    "print(\"Bag of Words & Naive Bayes Classifier accuracy: %0.3f\" % score)\n",
    "\n",
    "clf.fit(tfidf_train, y_train)\n",
    "pred4 = clf.predict(tfidf_test)\n",
    "score = accuracy_score(y_test, pred4)\n",
    "print(\"TF-IDF & Naive Bayes Classifier accuracy: %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-9.6428\t00             \t\t-5.4593\tsays           \n",
      "\t-9.6428\t02             \t\t-5.4626\tpercent        \n",
      "\t-9.6428\t04             \t\t-5.9386\tstate          \n",
      "\t-9.6428\t07             \t\t-6.0439\tyears          \n",
      "\t-9.6428\t1070           \t\t-6.0564\t000            \n",
      "\t-9.6428\t10932          \t\t-6.0961\ttax            \n",
      "\t-9.6428\t110            \t\t-6.0969\tyear           \n",
      "\t-9.6428\t111th          \t\t-6.1238\tstates         \n",
      "\t-9.6428\t112th          \t\t-6.2972\tmillion        \n",
      "\t-9.6428\t115            \t\t-6.3014\tpeople         \n",
      "\t-9.6428\t12189          \t\t-6.3554\thealth         \n",
      "\t-9.6428\t128            \t\t-6.4081\tcountry        \n",
      "\t-9.6428\t133            \t\t-6.4309\tobama          \n",
      "\t-9.6428\t137            \t\t-6.4479\tjobs           \n",
      "\t-9.6428\t13th           \t\t-6.4580\ttexas          \n",
      "\t-9.6428\t140            \t\t-6.5088\tcare           \n",
      "\t-9.6428\t156            \t\t-6.5335\ttaxes          \n",
      "\t-9.6428\t17th           \t\t-6.5406\tnew            \n",
      "\t-9.6428\t1888           \t\t-6.5503\tpresident      \n",
      "\t-9.6428\t190            \t\t-6.5861\taverage        \n"
     ]
    }
   ],
   "source": [
    "show_most_informative_features(count_vectorizer, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(X_test)\n",
    "results['pred'] = pred1\n",
    "results['actual'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>Go look on the West Point website and youll se...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5780</th>\n",
       "      <td>$120,000 will be spent by taxpayers on Charlie...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>What the facts say is ...the best scenario for...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>Says according to the FBI, more people are kil...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>Says Marco Rubio said that felons should not h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  pred  actual\n",
       "7527  Go look on the West Point website and youll se...     0       1\n",
       "5780  $120,000 will be spent by taxpayers on Charlie...     1       1\n",
       "76    What the facts say is ...the best scenario for...     0       0\n",
       "7129  Says according to the FBI, more people are kil...     1       1\n",
       "1822  Says Marco Rubio said that felons should not h...     0       0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      0.505102\n",
       "pred      0.505102\n",
       "actual    0.505102\n",
       "dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[(results['actual'] == 0) & (results['pred'] == 0)].count()/results[results['actual'] == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
